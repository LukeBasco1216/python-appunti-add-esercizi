{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPimYAETHdUKbSm02ZE0WEv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-gDHfp2kB-8e"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd \n","\n","df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ML 101.1/data/titanic.csv')\n","#  names = [] serve per sostituire tutti i nomi delle colonne \n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ML 101.1/data/car.data\", names = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class values\"])\n","# skiprows=[0] serve per saltare una o piu row specifiche, in questo caso usato per saltare la prima riga poiche i nomi delle colonne nel file erano nella seconda\n","df = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/ML 101.1/data/default of credit card clients.xls', skiprows=[0])"],"metadata":{"id":"lafWFSeEHxa4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# change the order of the columns: ( per convenienza, utilizzare se il target column e nel mezzo del df)\n","df = df.reindex(columns=['Age', 'Name'])\n","\n","#particolarita: \n","data = {'Name': ['Alice', 'Bob', 'Charlie'], \n","        'Age': [25, 30, 35], \n","        'City': ['New York', 'Chicago', 'Los Angeles'], \n","        'Gender': ['Female', 'Male', 'Male']}\n","df = pd.DataFrame(data)\n","df = df.reindex(columns=['Gender', 'Age', 'City', 'Name'])\n","# output:\n","# index  Gender  Age         City     Name\n","#   0    Female   25     New York    Alice\n","#   1      Male   30      Chicago      Bob\n","#   2      Male   35  Los Angeles  Charlie\n","\n","#######\n","\n","# eliminare una colonna:\n","df = df.drop(['ID'], axis = 1) # axis 0 sono rige 1 sono colonne, specificarlo poiche di default Ã¨ 0, in questo caso se non specificato eliminerebbe tutti i row con un'info('ID') uguale ad esso di qualsiasi colonna\n","\n","# piu colonne:\n","df = df.drop(['Name', 'Ticket', 'Cabin', 'Embarked'], axis = 1)\n","\n","#######\n","\n","# eliminare tutti i valori NAN\n","df = df.dropna()\n","\n","#se escono problemi potrebbe aiutare: .reset_index(drop=True)\n","\n","#######\n","\n","# trasformare tutti i dati in numeri di una colonna\n","df['Sex'] = (df['Sex'] == 'male').astype(int) # mette male come 1\n","\n","# se ci fossero piu di 2 tipi da sostituire fare il seguente modo:\n","# creare una sorta di lista di cio che vogliamo sostituire\n","gender_map = {'Male': 1, 'Female': 2, 'Non-binary': 3}\n","\n","# per la sostituzione\n","df['Gender'] = df['Gender'].replace(gender_map)\n","\n","# infine convertire il 'Gender' column a int da str\n","df['Gender'] = df['Gender'].astype(int)\n"],"metadata":{"id":"DFUkxpfILT5L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#per fare il tabulate\n","from tabulate import tabulate\n","\n","info = ['Alcohol', 'MA', 'Ash', 'AA', 'Magnesium', 'TP', 'Flavanoids', 'NF', 'PAc', 'CI', 'Hue', 'OD280/OD315', 'Proline']\n","daScoprire = [12.37, 1.07, 2.1, 18.5, 88, 3.52, 3.75, .24, 1.95, 4.5, 1.04, 2.77, 660] \n","print(tabulate([daScoprire], headers=info))"],"metadata":{"id":"e31FrC6QJG8f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualizzare il size per ogni classe\n","print(df.groupby('Class').size())\n","\n","# output: \n","# Class\n","# 1    59\n","# 2    71\n","# 3    48"],"metadata":{"id":"JwsTEVIkKP5Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# per fare il plot\n","%matplotlib inline\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","\n","sns.countplot(x=\"Class\", data=df)\n","plt.title(\"Diabetes Dataset\")\n","plt.xlabel(\"Classes\")\n","plt.ylabel(\"Counts\")\n","plt.show()"],"metadata":{"id":"jJqRTf1NKlPo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# trasformare in numpy per poter essere trattato dalla macchina\n","import numpy as np\n","dfnp = df.to_numpy()\n","\n","###\n","\n","# in questo caso i valori indipendenti(x) saranno dalla seconda colonna in poi e il target(y) sono tutti i row della prima colonna\n","x=dfnp[:,1:]\n","y=dfnp[:,0]\n","\n","# i valori indipendenti(x) saranno tutti i row dalla prima alla penultima colonna, mentre valori target(y) idem ma soltanto dell'ultima colonna\n","x=dfnumpy[:,:-1]\n","y=dfnumpy[:,-1] \n","\n","###\n","\n","# per visualizzare i primi valori\n","print(f'y = {x[:10]}')\n","print(f'y = {y[:10]}')\n","\n","# per togliere la dotazione scientifica e facilitare la lettura dei dati\n","np.set_printoptions(suppress=True)"],"metadata":{"id":"Esu4oLUmKoad"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# per contare il numero di classi e quante ne contiene, es: Counter({1.0: 59, 2.0: 71, 3.0: 48})\n","import collections\n","collections.Counter(y)"],"metadata":{"id":"SOBAgkABNl6Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# suddivisione dei dati per l'allenamento della macchina per il test di controllo dell'efficacita\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(x, y, \n","                                                    test_size = 0.30, # by default is 75%-25%\n","                                                    # shuffle is set True by default,\n","                                                    stratify = y, # per mantenere le proporzioni che ci sono nei dati di partenza\n","                                                    random_state = 123) # fix random seed for replicability"],"metadata":{"id":"_f_KcWscNyhi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Metodo KNN**"],"metadata":{"id":"C78bzRVZP3Qp"}},{"cell_type":"code","source":["# importiamo il metodo di classificazione K-NN\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","neighbors = KNeighborsClassifier(n_neighbors=5)\n","# allenamento\n","neighbors.fit(X_train,y_train)\n","# previsione\n","predict = neighbors.predict(X_test)\n","\n","print(f'dati predetti dal metodo =                {predict[:10]}') # dati predetti che potrebbero essere sbagliati\n","print(f'dati reali presenti nel dataset di test = {y_test[:10]}') # dati reali presi dal test\n"],"metadata":{"id":"VFA8v96nP6EZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install mlxtend\n","\n","# valutiamo il nostro metodo:\n","from mlxtend.plotting import plot_confusion_matrix\n","from matplotlib import pyplot as plt\n","from sklearn.metrics import confusion_matrix, classification_report\n","# visualizziamo la confusion matrix\n","plot_confusion_matrix(confusion_matrix(y_test, predict), cmap=plt.cm.Reds)\n","plt.show()"],"metadata":{"id":"2xAwB9RJP9I2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualizziamo adesso gli indicatori e la precisione guardando f1-score, piu alto piu accurato \n","print(classification_report(y_test, predict))"],"metadata":{"id":"ZmS-U658RSzQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Esempio per trovare il K migliore facendo il confronto con accuracy nel classification_report**"],"metadata":{"id":"z99xqvuEaY4n"}},{"cell_type":"code","source":["%matplotlib inline\n","import seaborn as sns\n","import matplotlib.pyplot as plt"],"metadata":{"id":"qxbXI5dRda9Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creare una lista nel quale verra salvato lo score dell'accuratezza di k\n","accuracy = []\n","# Will take some time\n","from sklearn import metrics\n","# scrivere un for loop che cambi k da 1 a 40\n","for k in range(1,41):\n","    neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n","    prediction = neigh.predict(X_test)\n","    accuracy.append(metrics.accuracy_score(y_test, prediction))\n","    \n","# plot\n","plt.figure(figsize=(10,6))\n","plt.plot(range(1,40),accuracy,color = 'blue',linestyle='dashed', \n","         marker='o',markerfacecolor='red', markersize=10)\n","plt.title('accuracy vs. K Value')\n","plt.xlabel('K')\n","plt.ylabel('Accuracy')\n","print(\"Maximum accuracy:-\",max(accuracy),\"at K =\",accuracy.index(max(accuracy)) + 1 ) # + 1 perche l'index parte da 0"],"metadata":{"id":"IcDFDQTkadw3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Esempio per trovare il K migliore facendo il confronto con weighted_avg nel classification_report**"],"metadata":{"id":"qMFdPba1evOU"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","\n","# creare una lista nel quale verra salvato lo score del weighted_avg di k\n","f1s_weighted_avg = []\n","\n","# Calculating f1 score for K values between 1 and 40\n","for i in range(1, 41):\n","    knn = KNeighborsClassifier(n_neighbors=i)\n","    knn.fit(X_train, y_train)\n","    pred_i = knn.predict(X_test)\n","    # using average='weighted' to calculate a weighted average for the 4 classes \n","    f1s_weighted_avg.append(f1_score(y_test, pred_i, average='weighted'))\n","\n","#plot\n","plt.figure(figsize=(12, 6))\n","plt.plot(range(1, 41), f1s_weighted_avg, color='red', linestyle='dashed', marker='o',\n","         markerfacecolor='blue', markersize=10)\n","plt.title('F1 Score K Value')\n","plt.xlabel('K Value')\n","plt.ylabel('F1 Score')\n","print(\"Maximum accuracy:-\",max(f1s_weighted_avg),\"at K =\",f1s_weighted_avg.index(max(f1s_weighted_avg)) + 1) # + 1 perche l'index parte da 0"],"metadata":{"id":"aJVYqapQez2z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Esempio per trovare il K migliore facendo il confronto con macro_avg nel classification_report**"],"metadata":{"id":"GLcPquJEfhXA"}},{"cell_type":"code","source":["# stesso codice di prima ma con un piccolo ritocco:\n","    f1s_weighted_avg.append(f1_score(y_test, pred_i, average='weighted')) \n","# average='weighted' a posto di weighted immettere macro"],"metadata":{"id":"Fzn9V9VTfjpT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **decision tree**"],"metadata":{"id":"5wiExdUeR3nN"}},{"cell_type":"code","source":["from sklearn import tree\n","\n","tree_clf = tree.DecisionTreeClassifier(criterion=\"gini\", # criteri per stabilire come splittare\n","                                       max_depth=4, # profonditÃ  dell'albero per evitare l'overfitting\n","                                       min_samples_split=30, # dimensione minima del sottogruppo a cui fermarsi (no more split)\n","                                       max_leaf_nodes=6, # numero dei nodi foglia\n","                                       min_samples_leaf=4 # numero di campioni per essere una foglia\n","                                      )\n","#allenamento\n","tree_clf.fit(X_train,y_train)\n","\n","# predizione\n","predict_dectree = tree_clf.predict(X_test)\n","\n","# visualizziamo il risultato (solo i primi dieci)\n","print(f'dati predetti dal metodo decision tree =  {predict_dectree[:10]}') # dati predetti dal metodo\n","print(f'dati reali presenti nel dataset di test = {y_test[:10]}') # dati effettivi presenti nel test set"],"metadata":{"id":"5lgjCK1IRkJX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install mlxtend\n","\n","# valutiamo il nostro metodo:\n","from mlxtend.plotting import plot_confusion_matrix\n","from matplotlib import pyplot as plt\n","from sklearn.metrics import confusion_matrix, classification_report\n","# visualizziamo la confusion matrix\n","plot_confusion_matrix(confusion_matrix(y_test, predict_dectree), cmap=plt.cm.Reds)# cmap=plt.cm.Reds solo per il colore\n","plt.show()"],"metadata":{"id":"11qj6uDcS-PC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y_test, predict_dectree))"],"metadata":{"id":"feyXHM1kTQt9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Esempio per trovare il depth migliore facendo il confronto con accuracy nel classification_report**"],"metadata":{"id":"GbAq1bc9gkVV"}},{"cell_type":"code","source":["# creare una lista nel quale verra salvato lo score dell'accuratezza di k\n","accuracy = []\n","# Will take some time\n","from sklearn import metrics\n","for depth in range(1,40):\n","  tree_clf = tree.DecisionTreeClassifier(criterion=\"gini\", # criteri per stabilire come splittare\n","                                       max_depth=depth, # profonditÃ  dell'albero per evitare l'overfitting\n","                                       min_samples_split=30, # dimensione minima del sottogruppo a cui fermarsi (no more split)\n","                                       max_leaf_nodes=6, # numero dei nodi foglia\n","                                       min_samples_leaf=4 # numero di campioni per essere una foglia\n","                                      )\n","  # prima parte: dobbiamo fare in modo che il metodo impari dalle informazioni a disposizione\n","  tree_clf.fit(X_train,y_train)\n","\n","  # seconda parte: vediamo se il metodo ha imparato bene facendogli prevedere i risultati \n","  predict_dt = tree_clf.predict(X_test)\n","  accuracy.append(metrics.accuracy_score(y_test, predict_dt))\n","    \n","#plot\n","plt.figure(figsize=(10,6))\n","plt.plot(range(1,40),accuracy,color = 'blue',linestyle='dashed', \n","         marker='o',markerfacecolor='red', markersize=10)\n","plt.title('accuracy vs. K Value')\n","plt.xlabel('K')\n","plt.ylabel('Accuracy')\n","print(\"Maximum accuracy:-\",max(accuracy),\"at K =\",accuracy.index(max(accuracy)) + 1 ) # + 1 perche l'index parte da 0"],"metadata":{"id":"QDUH1RBqgkB2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Esempio per trovare il depth migliore facendo il confronto con weighted_avg nel classification_report**"],"metadata":{"id":"GuRkoQ8vhmL9"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","\n","# invece di:\n","accuracy = []\n","accuracy.append(metrics.accuracy_score(y_test, predict_dt))\n","# diventa:\n","f1s = []\n","f1s.append(f1_score(y_test, predict_dt, average='weighted'))"],"metadata":{"id":"npDWD466hptg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Esempio per trovare il depth migliore facendo il confronto con macro_avg nel classification_report**"],"metadata":{"id":"YPkHaju0h26S"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","f1s.append(f1_score(y_test, predict_dt, average='macro'))"],"metadata":{"id":"4iw7oQR6h5Wk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **grafico conda**"],"metadata":{"id":"lsBzDjpeTY3Y"}},{"cell_type":"code","source":["# to be run only once, code for the installation of a new library and the related software\n","!conda update --force conda\n","!conda install graphviz\n","!conda install python-graphviz"],"metadata":{"id":"aMsYFwKMTc4U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#to be run every time. Tells your computer where to look for graphviz\n","import os\n","os.environ[\"PATH\"] += os.pathsep + 'C:\\\\Users\\\\wtitz\\\\Anaconda3\\\\Library\\\\bin\\\\graphviz'"],"metadata":{"id":"zhrC9zZzTfbo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features=list(df.columns.values) # (sono i nomi delle colonne del dataset)\n","features.remove('Class')\n","print(features)\n","\n","\n","import graphviz\n","dot_data = tree.export_graphviz(tree_clf, out_file=None, \n","                     feature_names=features,  \n","                     class_names=['0','1','2'], # !!!!!!!!!! questo dipende da quanti classi ci sono, o tipi di target?, esempio nel wine ci sono 3 classi per questo cosi, se ci fossero 2 classi sara: class_names=['0','1']\n","                     filled=True, rounded=True,  \n","                     special_characters=True)  \n","graph = graphviz.Source(dot_data)\n","graph.render('Wines')\n","graph"],"metadata":{"id":"EsJy3lHrTktp"},"execution_count":null,"outputs":[]}]}